{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "8ab46c2d_e8205241",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 6
      },
      "lineNbr": 0,
      "author": {
        "id": 1005097
      },
      "writtenOn": "2022-08-05T16:43:19Z",
      "side": 1,
      "message": "Unfortunately, though manually it passed, change doesn\u0027t seem to have an effect on image used for RGW:\n\nchanged: [controller-0] \u003d\u003e {\"changed\": true, \"cmd\": \"sudo cephadm shell 2\u003e/dev/null -- bash -c \\\"ceph orch ps | grep rgw | cut -d\u0027 \u0027 \n-f1 | xargs -n 1 -I {} ceph orch daemon redeploy {} --image undercloud-0.ctlplane.redhat.local:8787/rhceph/rhceph:5-235\\\"\\n\", \"delta\"\n: \"0:00:03.658293\", \"end\": \"2022-08-05 16:29:19.736065\", \"rc\": 0, \"start\": \"2022-08-05 16:29:16.077772\", \"stderr\": \"\", \"stderr_lines\"\n: [], \"stdout\": \"Scheduled to redeploy rgw.rgw.controller-0.yarfpa on host \u0027controller-0\u0027\\nScheduled to redeploy rgw.rgw.controller-1\n.fvjjts on host \u0027controller-1\u0027\\nScheduled to redeploy rgw.rgw.controller-2.jfpjql on host \u0027controller-2\u0027\", \"stdout_lines\": [\"Scheduled to redeploy rgw.rgw.controller-0.yarfpa on host \u0027controller-0\u0027\", \"Scheduled to redeploy rgw.rgw.controller-1.fvjjts on host \u0027controller-1\u0027\", \"Scheduled to redeploy rgw.rgw.controller-2.jfpjql on host \u0027controller-2\u0027\"]} \n\nbut 235 version is still not used (ceph orch ps | grep rgw still reports the newer image used)?\n\n",
      "revId": "6952686f1e3e42f315d3a6a5107661619b20fe07",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "35a6db17_a8284f84",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 6
      },
      "lineNbr": 0,
      "author": {
        "id": 1005097
      },
      "writtenOn": "2022-08-05T16:44:46Z",
      "side": 1,
      "message": "Also, this is as far I could get with it, next week I am wont be available so I have to leave this for someone else to continue here...",
      "parentUuid": "8ab46c2d_e8205241",
      "revId": "6952686f1e3e42f315d3a6a5107661619b20fe07",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "5ea1786c_391f0afe",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 6
      },
      "lineNbr": 0,
      "author": {
        "id": 1016970
      },
      "writtenOn": "2022-08-05T16:54:35Z",
      "side": 1,
      "message": "ah, I thought at the beginning the issue was related to the shell command.\nThe newer image takes some time to get redeployed, so if you check it after you schedule the redeploy you can\u0027t see it.",
      "parentUuid": "35a6db17_a8284f84",
      "revId": "6952686f1e3e42f315d3a6a5107661619b20fe07",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "fee4e9ef_0e725d5a",
        "filename": "plugins/tripleo-overcloud/docker_after_workaround.yml",
        "patchSetId": 6
      },
      "lineNbr": 40,
      "author": {
        "id": 1016970
      },
      "writtenOn": "2022-08-05T16:55:49Z",
      "side": 1,
      "message": "this is wrong, it requires some time until the cephadm orch schedule the new container, deletes the old reference and deploy the new one, so we should wait a few minutes.",
      "range": {
        "startLine": 40,
        "startChar": 10,
        "endLine": 40,
        "endChar": 76
      },
      "revId": "6952686f1e3e42f315d3a6a5107661619b20fe07",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    }
  ]
}