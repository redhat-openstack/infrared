{
  "comments": [
    {
      "key": {
        "uuid": "960fc267_02299e53",
        "filename": "plugins/virsh/defaults/topology/nodes/hcicephmon.yaml",
        "patchSetId": 2
      },
      "lineNbr": 5,
      "author": {
        "id": 1004632
      },
      "writtenOn": "2018-08-23T16:09:42Z",
      "side": 1,
      "message": "Please recheck this number,\ndefaults of a normal ceph/compute nodes are 6G each, a dedicated monitor node is 4G,\nCan\u0027t we live with lower than 32G as default?",
      "range": {
        "startLine": 5,
        "startChar": 8,
        "endLine": 5,
        "endChar": 15
      },
      "revId": "d624a4bdfa36e0aef062ced48c5d78ca9938f248",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "51e26cdb_bbb9c596",
        "filename": "plugins/virsh/defaults/topology/nodes/hcicephmon.yaml",
        "patchSetId": 2
      },
      "lineNbr": 16,
      "author": {
        "id": 1004632
      },
      "writtenOn": "2018-08-23T16:09:42Z",
      "side": 1,
      "message": "Please recheck this as well, \nI think that disk size is more critical then mem size,\nThis 6 disks node is 100G, while a normal ceph is 65G.\nShouldn\u0027t we choose other defaults?",
      "range": {
        "startLine": 16,
        "startChar": 15,
        "endLine": 16,
        "endChar": 18
      },
      "revId": "d624a4bdfa36e0aef062ced48c5d78ca9938f248",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735",
      "unresolved": true
    }
  ]
}