---
# Any step that should happen before initiating the osp-d playbook
# This could be validation of the hosts, package installation that is assumed as per the guide, etc..
- name: Prepare our undercloud
  hosts: hypervisor
  gather_facts: yes
  any_errors_fatal: true
  vars_files:
      - vars/topology/undercloud.yml
  vars:
      undercloud_image_file: "{{ install.quickstart.image | basename }}"
      undercloud_disk_path: "{{ install.disk.pool }}/{{ install.quickstart.filename.rstrip('.qcow2') | basename }}-disk1.qcow2"
      undercloud_user: "{{ install.user.name | default('stack') }}"
      # todo(yfried): add external refs so users can override these values and customize the Undercloud
  tasks:
      - name: check and create directory
        file:
          path: "{{ undercloud_disk_path }}"
          state: directory
          owner: root
          group: root
          mode: 0755
        when: undercloud_disk_path | default(False)

      - name: download image
        get_url:
            url: "{{ install.quickstart.image }}"
            dest: "{{ undercloud_disk_path }}"
            owner: qemu
            group: qemu
            force: yes

      - name: install libguestfs-tool / virt-customize
        package:
            name: libguestfs-tools
            state: present

      - name: resets undercloud image configurations
        environment:
            LIBGUESTFS_BACKEND: direct
        command: >
            virt-sysprep -a {{ undercloud_disk_path }}
                --operations dhcp-client-state,dhcp-server-state,net-hostname,net-hwaddr,udev-persistent-net,ssh-hostkeys
      # Copy hypervisor's key into UC root and also for "undercloud_user" as we need this user since next hosts task update inventory
      # This is necesarry for muffin because we need to refresh the auhtortized_keys with new hypervisor's pubkey
      - name: inject our key into the undercloud image
        command: >
            virt-customize -a {{ undercloud_disk_path }}
               --root-password password:redhat
               --mkdir /root/.ssh
               --chmod 0700:/root/.ssh
               --upload /root/.ssh/id_rsa.pub:/root/.ssh/authorized_keys
               --upload /root/.ssh/id_rsa.pub:/home/{{ undercloud_user }}/.ssh/authorized_keys
               --chmod 0700:/home/{{ undercloud_user }}/.ssh
               --run-command "chown {{ undercloud_user }}:{{ undercloud_user }} /home/{{ undercloud_user }}/.ssh/authorized_keys"
               --selinux-relabel

      - name: create Undercloud VM from snapshot
        command: >
            virt-install --name {{ undercloud_node.name }}
               --disk path={{ undercloud_disk_path }},device=disk,bus=virtio,format=qcow2,cache={{ undercloud_node.disks.disk1.cache }}
               --network network:data
               --network network:management
               --network network:external
               --virt-type kvm
               --cpu host-model
               --ram {{ undercloud_node.memory }}
               --vcpus {{ undercloud_node.cpu }}
               --os-variant {{ undercloud_node.os.variant }}
               --import
               --noautoconsole
               --autostart
               --vnc
               --rng /dev/urandom
               --dry-run --print-xml
        register: virt_xml

      - name: define the undercloud VM
        virt:
            name: "{{ undercloud_node.name }}"
            command: define
            xml: "{{ virt_xml.stdout }}"

      - name: get correct MAC of external interface for undercloud (in case we have multiple dhcp leases in libvirt's db)
        shell: |
            virsh dumpxml undercloud-0 | grep external -B 1 | grep mac | cut -d\' -f2
        register: mac_ext

      - name: start the undercloud VM
        virt:
            name: "{{ undercloud_node.name }}"
            state: running

      #TODO(yfried): cleanup should be in a block/allways format
      # todo: make this optional
#      - name: remove quickstart tar file
#        file:
#            state: absent
#            path: "{{ undercloud_image_file }}.{{ (tar is defined) | ternary('tar', 'qcow2') }}"

      - name: wait for the undercloud IP to become available
        shell: |
            virsh net-dhcp-leases external | grep {{ mac_ext.stdout }} | awk '($4 == "ipv4") && ($6 =="{{ undercloud_node.name }}") {print $5}'
        register: undercloud_ip
        until: undercloud_ip.stdout != ''
        retries: 15
        delay: 15

      - name: waiting for the undercloud to be SSH available
        wait_for:
            port: 22
            host: "{{ undercloud_ip.stdout | ipaddr('address') }}"
            search_regex: OpenSSH
        delay: 10

      - name: add undercloud to host list
        add_host:
            name: "{{ undercloud_node.name }}"
            hostname: "undercloud-0"
            node_label: "undercloud-0"
            groups: "undercloud,tester,openstack_nodes"
            ansible_ssh_user: "{{ undercloud_user }}"
            ansible_ssh_private_key_file: "{{ hostvars[groups['overcloud_nodes'][0]].ansible_ssh_private_key_file }}"
            ansible_ssh_host: "{{ undercloud_ip.stdout | ipaddr('address') }}"
            ansible_ssh_common_args: "
                -o ForwardAgent=yes
                -o IdentitiesOnly=yes
                -o ServerAliveInterval=30
                -o ControlMaster=auto
                -o ControlPersist=30m
                -o StrictHostKeyChecking=no
                -o UserKnownHostsFile=/dev/null
                -o ProxyCommand=\"ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -W %h:%p -i {{ ansible_ssh_private_key_file }} {{ ansible_ssh_user }}@{{ ansible_ssh_host }}\""
        notify:
            - update /etc/hosts with undercloud's details

      - include_role:
            name: inventory-update
        delegate_to: localhost
        vars:
            inventory_file_name: 'hosts-installer'

      # create stack user on hypervisor, because on clean machine we can have it missing
      - block:
          - name: create stack user on hypervisor
            user:
                name: "{{ install.user.name }}"
                state: present
                password: "{{ install.user.password | password_hash('sha512') }}"

          - name: set permissions for the user to access the hypervisor
            copy:
                content: |
                    [libvirt Management Access]
                    Identity=unix-user:{{ install.user.name }}
                    Action=org.libvirt.unix.manage
                    ResultAny=yes
                    ResultInactive=yes
                    ResultActive=yes
                dest: "/etc/polkit-1/localauthority/50-local.d/50-libvirt-user-{{ install.user.name }}.pkla"

      - name: test openstack environment
        delegate_to: "{{ groups.undercloud | first }}"
        become: true
        become_user: stack
        shell: |
            source ~/stackrc
            openstack server list
        tags: skip_ansible_lint

  handlers:
      - name: update /etc/hosts with undercloud's details
        lineinfile:
            dest: "/etc/hosts"
            line: "{{ hostvars[groups['undercloud'][0]].ansible_ssh_host }}    {{ groups['undercloud'][0] }}.redhat.local {{ groups['undercloud'][0] }}"
            state: present

# workaround for selinux errors while introspection from qs image
- name: fix selinux configurations
  hosts: undercloud
  become: true
  gather_facts: yes
  any_errors_fatal: true
  tasks:
      - name: Change setype of /httpboot/ to httpd_sys
        file:
            path: /httpboot
            setype: httpd_sys_content_t
            recurse: yes

# need to setup shade node after restore
- import_playbook: shade.yml
  tags: restore_shade

# update clouds.yml basing on the starckrc file from the restored undercloud
- name: update clouds.yml
  hosts: undercloud
  gather_facts: no
  any_errors_fatal: true
  tags: restore_clouds_yml
  tasks:
      - name: update clouds.yaml file
        include_tasks: clouds.yml
        vars:
            auth_file_path: "/home/stack/stackrc"
            cloudname: "undercloud"

- name: print core/director puddle version
  hosts: undercloud
  gather_facts: no
  any_errors_fatal: false
  tags: restore_puddle_version
  tasks:
      - stat:
            path: ~/core_puddle_version
        register: puddle_file

      - name: get core puddle version from ~/core_puddle_version
        command:  cat ~/core_puddle_version
        register: core_puddle_file
        when: puddle_file.stat.exists

      - name: get core puddle version from repos
        shell: cat /etc/yum.repos.d/rhos-release-[0-9]*.repo | grep ^baseurl.*/OpenStack/ | grep -v latest | awk -F / '{print $8 }' | tail -n 1
        register: core_puddle_repos
        when: puddle_file.stat.exists == False

      - debug:
            msg: "Build mark: core_puddle={{ puddle_file.stat.exists|ternary (core_puddle_file.stdout, core_puddle_repos.stdout) }}"

      - find:
            use_regex: yes
            patterns: '^rhos-release-\d+-director.repo$'
            paths:
                - '/etc/yum.repos.d/'
        register: director_repo_result

      - name: get director puddle version
        shell: "cat {{ director_repo_result.files[0].path }} | grep ^baseurl.*/OpenStack/ | grep -v latest | awk -F / '{print $8 }' | tail -n 1"
        register: director_puddle
        when: director_repo_result.matched > 0

      - debug:
            msg: "Build mark: director_puddle={{ director_puddle.stdout }}"
        when: director_repo_result.matched > 0
