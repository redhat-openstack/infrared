- name: Ensure that time is right everywhere
  hosts: "undercloud:overcloud_nodes"
  gather_facts: false
  any_errors_fatal: true
  tasks:
    - name: Populate service facts
      service_facts:
      no_log: true

    - name: Reset the time if ntpd service
      become: true
      when:
        - "'ntpd.service' in ansible_facts.services"
        - ansible_facts.services['ntpd.service'].state == "running"
      block:
      - name: Stop the time service
        service:
          name: ntpd
          state: stopped
      - name: Reset the time
        shell: >-
          ntpd -q -g -x
        changed_when: false
      - name: Start the time service
        service:
          name: ntpd
          state: started

    - name: Reset the time if chronyd
      become: true
      when:
        - "'chronyd.service' in ansible_facts.services"
        - ansible_facts.services['chronyd.service'].state == "running"
      block:
      - name: Reset the time
        shell: >-
          chronyc makestep
        changed_when: false

- name: Ensure that the Ceph cluster is up and healthy
  hosts: "{{ ('monitors' in groups) | ternary('monitors', ('serviceapi' in groups) | ternary('serviceapi', 'controller')) }}"
  gather_facts: false
  any_errors_fatal: true
  tasks:
    - name: Only run this on one of the hosts
      run_once: true
      when: "'ceph' in groups"
      block:
      - name: Get a name of Ceph cluster
        become: true
        shell: |
          set -o pipefail
          ps -p $(pidof ceph-mon) -o args --no-headers | grep -o 'cluster.*' | cut -d' ' -f2
        changed_when: false
        register: ceph_cluster_name

      - name: Identify the container runtime (if any)
        shell: |-
          runtime=$(command -v podman || command -v docker)
          if [[ $runtime != '' ]]; then
            basename $runtime
          else
            echo none
          fi
        register: _container_runtime
        changed_when: false

      - name: Set the ceph command prefix
        set_fact:
          _ceph_cmd_prefix: >-
            {% if _container_runtime.stdout != "none" %}
            {{ _container_runtime.stdout }}
            exec
            ceph-mon-{{ inventory_hostname }}
            {% endif %}
            ceph
            -c
            /etc/ceph/{{ ceph_cluster_name.stdout }}.conf

      # Json format for osd stat is inconsistent across ceph versions
      # Because of it we need to create separate osd stat command in advance
      - name: Set the ceph osd command
        set_fact:
          _ceph_osd_cmd_prefix: >-
            {{ _ceph_cmd_prefix }}
            osd
            stat
            --format
            json
            {% if _container_runtime.stdout == "podman" %}
            | jq ".[]"
            {% endif %}

      - name: Wait for all OSDs to be up
        become: true
        shell: |
          set -o pipefail
          {{ _ceph_osd_cmd_prefix }}
        register: _wait_for_all_osds_up
        retries: 5
        delay: 60
        changed_when: false
        until:
          - (_wait_for_all_osds_up.stdout | from_json)["num_osds"] | int > 0
          - (_wait_for_all_osds_up.stdout | from_json)["num_osds"] == (_wait_for_all_osds_up.stdout | from_json)["num_up_osds"]

      - name: Wait for cluster health to be OK
        become: true
        command: >-
          {{ _ceph_cmd_prefix }} status
        changed_when: false
        register: _ceph_health
        until: _ceph_health.stdout.find("HEALTH_OK") > -1
        retries: 15
        delay: 60
        failed_when: (_ceph_health.stdout.find("HEALTH_OK") == -1) and
                     (_ceph_health.stdout.find("HEALTH_WARN") == -1)

- name: Ensure that the Pacemaker cluster and all its resources are up
  hosts: controller:!serviceapi
  gather_facts: false
  any_errors_fatal: true
  tasks:
    - block:
        - name: Wait for core cluster hosts to come online
          shell: |
            set -o pipefail
            crm_mon -1 | grep -w 'Online:' | grep {{ inventory_hostname }}
          changed_when: false
          register: _pcs_status
          retries: 5
          delay: 60
          until: _pcs_status is not failed

        - name: Wait for the resources to come online
          shell: |
            crm_mon -1
          changed_when: false
          register: _bundle_status
          retries: 5
          delay: 60
          until:
            - not(_bundle_status.stdout is search("Stopped.*" ~ inventory_hostname))
            - not(_bundle_status.stdout is search("Starting.*" ~ inventory_hostname))

        - name: Wait for cluster to be OK
          shell: |
            crm_mon -s
          changed_when: false
          register: _pcs_health
          retries: 5
          delay: 60
          until: _pcs_health.stdout.find("CLUSTER OK") > -1
          run_once: true
      become: true

- name: Ensure that all the core OpenStack services/agents are up
  hosts: undercloud
  gather_facts: false
  any_errors_fatal: true
  vars:
    overcloud_rc: "/home/stack/{{ _overcloud_stack_name.stdout }}rc"
  tasks:
    - name: Discover the overcloud stack name
      shell: |
        source /home/stack/stackrc
        openstack stack list -c 'Stack Name' -f value
      register: _overcloud_stack_name
      changed_when: false

    - name: Force some services to reinitiate RabbitMQ connectivity
      become: true
      shell: |-
        {%- raw -%}
        return_code=0
        runtime=$(command -v podman || command -v docker)
        if [[ "${runtime}" != "" ]]; then
          for cnt in $(${runtime} ps --format "{{.Names}}" | grep -E "neutron_.*|nova_metadata" | grep -v ".*_api"); do
            echo "Restarting ${cnt}"
            ${runtime} restart ${cnt}
            return_code=2
          done
        else
          for svc in $(systemctl --no-legend list-units neutron\*agent.service | awk '{print $1}'); do
            echo "Restarting ${svc}"
            systemctl restart ${svc}
            return_code=2
          done
        fi
        exit ${return_code}
        {%- endraw %}
      delegate_to: "{{ item }}"
      loop: "{{ groups['overcloud_nodes'] }}"
      register: _restart_services
      changed_when: _restart_services.rc == 2
      failed_when: _restart_services.rc not in [0,2]

    # OSP10 returns: { "State": "UP", "Alive": false }
    # OSP13+ returns: { "State": "UP", "Alive": "XXX" }
    - name: Wait until all network agents are up
      shell: |
        source {{ overcloud_rc }}
        openstack network agent list -f json | jq '.[] | select(.State=="UP" and (.Alive==false or .Alive=="XXX"))'
      changed_when: false
      register: _network_agents_state
      retries: 15
      delay: 60
      until: _network_agents_state.stdout == ''

    - name: Wait until all compute services are up
      shell: |
        source {{ overcloud_rc }}
        openstack compute service list -f json | jq '.[] | select(.Status=="enabled" and .State=="down")'
      changed_when: false
      register: _compute_service_state
      retries: 15
      delay: 60
      until: _compute_service_state.stdout == ''

    - name: Wait until all volume services are up
      shell: |
        source {{ overcloud_rc }}
        openstack volume service list -f json | jq '.[] | select(.Status=="enabled" and .State=="down" and .Binary!="cinder-backup")'
      changed_when: false
      register: _volume_service_state
      retries: 15
      delay: 60
      until: _volume_service_state.stdout == ''

    # ref:
    #   https://bugzilla.redhat.com/show_bug.cgi?id=1665191
    #   https://bugzilla.redhat.com/show_bug.cgi?id=1666804
    - name: Verify that at least one cinder-backup service is active (if it was deployed)
      shell: |
        source {{ overcloud_rc }}
        RETURN_CODE=0
        if [[ $(openstack volume service list -f json | jq '.[] | select(.Binary=="cinder-backup" and .Status=="enabled")') != '' ]]; then
          if [[ $(openstack volume service list -f json | jq '.[] | select(.Binary=="cinder-backup" and .Status=="enabled" and .State=="up").Host' | wc -l) -lt "1" ]]; then
            RETURN_CODE=1
          fi
        fi
        exit ${RETURN_CODE}
      changed_when: false
      register: _volume_backup_state
      retries: 15
      delay: 60
      until: _volume_backup_state.rc == 0
