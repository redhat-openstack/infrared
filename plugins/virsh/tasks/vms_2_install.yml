---
- set_fact:
    topology_node: "{{ node.value }}"

- name: Set default node_start_index
  set_fact:
      node_start_index: 0

- name: define disk pool path
  set_fact:
      disk_pool: "{{ provision.disk.pool if (topology_node.disks.disk1.path == None) else topology_node.disks.disk1.path }}"

- name: Calculate node_start_index
  set_fact:
      node_start_index: "{{ node_start_index|int + 1 if (topology_node.name + '-' in item) and hostvars[item].get('ansible_connection') == 'ssh' else node_start_index|int }}"
  with_items: "{{ groups.all }}"
  when: provision.topology.extend | default(False)

  # This is an early inventory host registration.
  # It has 'local' connection type because has no configured network yet.
  # This is needed for cases when provisioning failed before we generated inventory file. In this cases we have orphan resources (vms and networks).
  # Early inventory generation adds host to inventory and generates new file right before virt-install.
  # If host in inventory but there is no corresponding  VM it will not cause a fail.
- name: add hosts to host list
  add_host:
      name: "{{ topology_node.name }}-{{ item }}"
      ansible_connection: "local"
  with_sequence: start={{ node_start_index|int }} end={{ topology_node.num|int + node_start_index|int - 1 }}

- include_role:
      name: inventory-update
      apply:
          delegate_to: localhost
  vars:
      inventory_file_name: 'hosts-prov'

- name: create VM bridges for interfaces that don't belong to any network
  include_tasks: create_bridges.yml
  when: item.bridged|default(false)
  with_items: "{{ topology_node.interfaces }}"

- block:
      - set_fact:
            serial_files_dir: /var/log/sfiles
      - name: Redirect serial output to files - Make a directory
        file:
            path: "{{ serial_files_dir }}"
            state: directory
            mode: 0755

      - name: Redirect serial output to files - Create files
        copy:
            content: ""
            dest: "{{ serial_files_dir}}/{{ prefix|default('') }}{{ topology_node.name }}-{{ item }}.log"
            force: yes
            mode: 0644
        with_sequence: start={{ node_start_index|int }} end={{ topology_node.num|int + node_start_index|int - 1 }}
  when: provision.serial.files


# For installation the parallel run should be on the creation of the VMs as the amount is what needs to be paralleled
- name: create vm's
  shell: |
      virt-install --name {{ topology_node.name }}-{{ item }} \
          {% if topology_node.disks|count > 0 %}
          {% for disk_name, disk_values in topology_node.disks.items() %}
          {% if disk_values.import_url is defined and disk_values.import_url %}
           --disk path={{ base_image_path }}/{{ topology_node.name }}-{{ item }}-{{ disk_name }}.qcow2,device=disk,bus=
           {%- if topology_node.disks.disk1.bus is defined %}{{ topology_node.disks.disk1.bus }}{% else %}{{ provision.disk.bus }}{% endif %},format=qcow2,cache={{ disk_values.cache }} \
          {% else %}
           --disk path={{ disk_pool }}/{{ topology_node.name }}-{{ item }}-{{ disk_name }}.qcow2,device=disk,bus={{ provision.disk.bus }},format=qcow2,cache={{ disk_values.cache }} \
          {% endif -%}
          {% endfor %}
          {% else %}
          --disk none \
          {% endif %}
          {% if provision.bootmode == 'uefi' %}
          --boot {{ 'hd' if topology_node.deploy_os|default(True) else 'uefi' }} \
          {% else %}
          --boot {{ provision.bootmode }} \
          {% endif %}
          {% for interface in topology_node.interfaces %}
           --network {{ 'bridge' if (interface.bridged|default(False)) else 'network' }}:{{ prefix|default('') }}{{(prefix is defined|ternary('-',''))}}
           {%- if interface.needs_formatting | default(False) %}{{ interface.network | format(item) }}{% else %}{{ interface.network }}{% endif %}
           {%- if interface.model is defined and interface.model %},model={{ interface.model }}{% endif %} \
          {% endfor -%}
          {% if provision.serial.files %}
           --serial file,path="{{ serial_files_dir}}/{{ prefix|default('') }}{{ topology_node.name }}-{{ item }}.log" \
          {% endif %}
           --virt-type kvm \
           --cpu {{ topology_node.cpumodel|default('host-passthrough') }} \
           --ram {{ topology_node.memory }} \
           {% if provision.hyperthreading.enabled.nodes is defined %}
             {% for node in provision.hyperthreading.enabled.nodes %}
              {% if node == topology_node.name %}
            --vcpus={{ topology_node.cpu }},maxvcpus={{ 2 * (topology_node.cpu | int) }},threads=2 \
              {% endif %}
             {% endfor %}
           {% else %}
            --vcpus {{ topology_node.cpu }} \
           {% endif %}
           --os-variant {{ topology_node.os.variant }} \
           --import \
           --noautoconsole \
           --autostart \
           --vnc \
           --rng /dev/urandom {{ provision.get('virtopts', '') }}
  with_sequence: start={{ node_start_index|int }} end={{ topology_node.num|int + node_start_index|int - 1 }}
  register: vm_install
  async: 7200
  poll: 0

- name: save install jids
  set_fact:
      async_install: "{{ async_install|default([]) + vm_install.results|map(attribute='ansible_job_id')|list }}"
