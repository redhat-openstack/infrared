---
- name: Provision VMs
  hosts: "{{ (_run_condition | bool) | ternary('hypervisor', 'none') }}"
  gather_facts: yes
  any_errors_fatal: true
  vars:
      base_image_path: /var/lib/libvirt/images
      url: "{{ provision.image.url }}"
      infrared_vswitch_types:
        - vqfx
        - veos
        - ovsvswitch
  tasks:
    - name: Expand ansible local facts (needed for topology extend)
      set_fact:
        ansible_local: "{{ ansible_local | combine({'run': ansible_local.deployment_info}) }}"
      when:
        - provision.prefix is defined
        - provision.topology.extend
        - ansible_local.run is not defined

    - name: Get uniq id for current deployment
      set_fact:
        prefix: "{{ provision.prefix }}"
      when: provision.prefix is defined

    - name: set vswitch type default
      set_fact:
        vswitch_type: 'None'

    - name: set vswitch type
      set_fact:
        vswitch_type: "{{ switch_type }}"
      with_list: "{{ infrared_vswitch_types }}"
      loop_control:
          loop_var: switch_type
      when: switch_type in provision.topology.nodes|join('')

    - name: load nodes topology configuration
      include_tasks: tasks/load_topology.yml
      with_dict: "{{ provision.topology.nodes }}"
      loop_control:
          loop_var: node

    - name: provision image for each node
      include_tasks: tasks/download_images.yml
      with_dict: "{{ topology_nodes }}"
      loop_control:
          loop_var: node
      when: node.value.node_indexes|length > 0
      tags: images

    - name: prepare bridge interfaces in the topology
      set_fact:
        topology_nodes: "{{ topology_nodes | wirenodes }}"

    # Create Disks
    - block:
        - name: create disks for each VM if not import
          include_tasks: tasks/vms_1_create_disk.yml
          with_dict: "{{ topology_nodes }}"
          loop_control:
              loop_var: node
          when: node.value.node_indexes|length > 0

        - name: Wait for all disks to be created
          async_status:
              jid: "{{ item }}"
          register: disk_tasks
          until: disk_tasks.finished
          retries: 300
          with_items: "{{ async_disks }}"
          when: async_disks is defined
      tags: disks

    # Build VMs
    - block:
        - name: define libvirt VMs
          include_tasks: tasks/vms_2_install.yml
          with_dict: "{{ topology_nodes }}"
          loop_control:
              loop_var: node
          when: node.value.node_indexes|length > 0

        - name: Wait for VMs to be created
          async_status:
              jid: "{{ item }}"
          register: install_tasks
          until: install_tasks.finished
          retries: 300
          with_items: "{{ async_install }}"
          when: async_install is defined
      tags: install

    # Fetch IP addresses
    - block:
        - name: Get VMs hardware adresses
          include_tasks: tasks/vms_3_hwaddr.yml
          with_dict: "{{ topology_nodes }}"
          loop_control:
              loop_var: node
          when: node.value.node_indexes|length > 0

        # add_host inside tasks/netip_natted.yml, bypasses the play host loop
        # and only runs once for all the hosts in the play. To force add_host
        # to run on all hypervisors, we use this list to run tasks sequentially
        # on hosts i.e move to next after fininshing the previous host
        - name: Set ip VMs ip addresses and add to inventory
          include_tasks: tasks/netip_natted.yml
          with_list:
            - "{{ inventory_hostname }}"
          loop_control:
              loop_var: addhost
          when: "(vm_inv_info is defined) and (not topology_node.external_network.bridged|default(False))"
      tags: ips

    - name: Post-configure VMs
      include_tasks: tasks/vms_4_post_configure.yml
      with_dict: "{{ topology_nodes }}"
      loop_control:
          loop_var: node
      when: node.value.node_indexes|length > 0
