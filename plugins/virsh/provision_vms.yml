---
- name: Provision VMs
  hosts: "{{ (_run_condition | bool) | ternary('hypervisor', 'none') }}"
  gather_facts: yes
  any_errors_fatal: true
  vars:
      appliance_version: '1.40.1'
      appliance_checksum: 'sha1:525522aaf4fcc4f5212cc2a9e98ee873d125536e'
      base_image_path: /var/lib/libvirt/images
      url: "{{ provision.image.url }}"
      infrared_vswitch_types:
        - vqfx
  tasks:
    - name: Get uniq id for current deployment
      set_fact:
            prefix: "{{ ansible_local.run.keys()[0] }}"
      when: provision.prefix is defined

    - name: load nodes topology configuration
      include_tasks: tasks/load_topology.yml
      with_dict: "{{ provision.topology.nodes }}"
      loop_control:
          loop_var: node

    - name: Get Appliance files to allow virt-customize on RHEL hypervisors
      get_url:
          dest: /opt/appliance-{{ appliance_version }}.tar.xz
          checksum: "{{ appliance_checksum }}"
          url: http://download.libguestfs.org/binaries/appliance/appliance-{{ appliance_version }}.tar.xz
      register: appliance_archive

    - name: Unpack Appliance files
      when: appliance_archive is changed
      unarchive:
        src: "{{ appliance_archive.dest }}"
        dest: /opt/
        remote_src: yes

    - name: provision image for each node
      include_tasks: tasks/download_images.yml
      with_dict: "{{ topology_nodes }}"
      loop_control:
          loop_var: node
      when: node.value.node_indexes|length > 0
      tags: images

    - name: prepare bridge interfaces in the topology
      set_fact:
        topology_nodes: "{{ topology_nodes | wirenodes }}"

    # Create Disks
    - block:
        - name: create disks for each VM if not import
          include_tasks: tasks/vms_1_create_disk.yml
          with_dict: "{{ topology_nodes }}"
          loop_control:
              loop_var: node
          when: node.value.node_indexes|length > 0

        - name: Wait for all disks to be created
          async_status:
              jid: "{{ item }}"
          register: disk_tasks
          until: disk_tasks.finished
          retries: 300
          with_items: "{{ async_disks }}"
          when: async_disks is defined
      tags: disks

    # Build VMs
    - block:
        - name: define libvirt VMs
          include_tasks: tasks/vms_2_install.yml
          with_dict: "{{ topology_nodes }}"
          loop_control:
              loop_var: node
          when: node.value.node_indexes|length > 0

        - name: Wait for VMs to be created
          async_status:
              jid: "{{ item }}"
          register: install_tasks
          until: install_tasks.finished
          retries: 300
          with_items: "{{ async_install }}"
          when: async_install is defined
      tags: install

    # Fetch IP addresses
    - block:
        - name: Get VMs hardware adresses
          include_tasks: tasks/vms_3_hwaddr.yml
          with_dict: "{{ topology_nodes }}"
          loop_control:
              loop_var: node
          when: node.value.node_indexes|length > 0

        # add_host inside tasks/netip_natted.yml, bypasses the play host loop
        # and only runs once for all the hosts in the play. To force add_host
        # to run on all hypervisors, we use this list to run tasks sequentially
        # on hosts i.e move to next after fininshing the previous host
        - name: Set ip VMs ip addresses and add to inventory
          include_tasks: tasks/netip_natted.yml
          with_list:
            - "{{ inventory_hostname }}"
          loop_control:
              loop_var: addhost
          when: "(vm_inv_info is defined) and (not topology_node.external_network.bridged|default(False))"
      tags: ips

    - name: Post-configure VMs
      include_tasks: tasks/vms_4_post_configure.yml
      with_dict: "{{ topology_nodes }}"
      loop_control:
          loop_var: node
      when: node.value.node_indexes|length > 0
