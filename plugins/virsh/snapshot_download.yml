---
- name: Download snapshots of virtual machines
  hosts: "{{ (_run_condition | bool) | ternary('hypervisor', 'none') }}"
  gather_facts: yes
  any_errors_fatal: true
  vars:
    _object_storage_client_venv_path: "{{ provision.virsh.snapshot.path | dirname }}/.awsclientvenv"
  tasks:
    - name: Check that the required environment variables are set
      fail:
        msg: >-
          The environment variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY
          must be set on the Ansible controller.
      when:
        - _object_storage_client_bin == "aws"
        - lookup('env', 'AWS_ACCESS_KEY_ID') == ""
        - lookup('env', 'AWS_SECRET_ACCESS_KEY') == ""

    - name: Ensure a usable object storage client is available
      include_role:
        name: create_venv
      vars:
        venv_destination_path: "{{ _object_storage_client_venv_path }}"
        venv_owner_match_to_parent: yes
        venv_pip_packages:
          - "awscli"
        venv_shebang_relocate: yes

    - name: Make sure that the snapshot path exists
      file:
        path: "{{ provision.virsh.snapshot.path }}"
        state: directory

    - name: Download the image set, but clean up if there is a failure
      block:
        # The ansible s3_sync module does not currently support the s3_url parameter
        # which would allow it to work with Ceph RGW.
        # The ansible aws_s3 module supports the s3_url, but requires the upload of
        # each object to be done in a loop which is highly inefficient.
        # We use the 'aws s3 sync' option due to it being able to work on the whole
        # folder at once with a high level of efficiency.
        - name: Download the container contents to the snapshot path folder
          vars:
            _cli_aws_endpoint_url: "{{ (lookup('env', 'AWS_ENDPOINT_URL') != '') | ternary('--endpoint-url ' ~ lookup('env', 'AWS_ENDPOINT_URL'), '') }}"
          shell: |
            source {{ _object_storage_client_venv_path | basename }}/bin/activate
            if ! aws {{ _cli_aws_endpoint_url }} s3 ls {{ provision.virsh.snapshot.container }}/{{ provision.virsh.snapshot.path | basename }}; then
              echo "There are no files available for an image set named: {{ provision.virsh.snapshot.path | basename }}"
              exit 1
            else
              aws {{ _cli_aws_endpoint_url }} s3 sync --no-progress --delete {{ provision.virsh.snapshot.container }}/{{ provision.virsh.snapshot.path | basename }} {{ provision.virsh.snapshot.path | basename }}/
            fi
          args:
            executable: "/bin/bash"
            chdir: "{{ provision.virsh.snapshot.path | dirname }}"
          environment:
            AWS_ACCESS_KEY_ID: "{{ lookup('env', 'AWS_ACCESS_KEY_ID') }}"
            AWS_SECRET_ACCESS_KEY: "{{ lookup('env', 'AWS_SECRET_ACCESS_KEY') }}"
          register: _virsh_snapshot_download_aws_result
          retries: 10
          delay: 30
          until: _virsh_snapshot_download_aws_result is success
      rescue:
        - name: Clean up the snapshot path
          file:
            path: "{{ provision.virsh.snapshot.path }}"
            state: absent
          when:
            - provision.virsh.snapshot.cleanup | bool

        - name: Fail after the cleanup
          fail:
            msg: "The image set download failed."
