- name: Overcloud Ceph Reboot
  hosts: ceph:!unused
  gather_facts: false
  any_errors_fatal: true
  serial: 1
  vars:
      ceph_client: "{{ groups['controller']|first }}"
      container_runtime: "{{ (install.version | default(undercloud_version) | openstack_release > 14) | ternary('podman', 'docker') }}"
      overcloud_version: "{{ install.version | default(undercloud_version) | openstack_release }}"
  tasks:
      - set_fact:
            overcloud_rc: "/home/stack/{{ install.overcloud.stack }}rc"
      # Sort out ceph client
      - name: Set ceph client to be the dedicated ceph monitor node if present
        set_fact:
          ceph_client: "{{ groups['monitors']|first }}"
        when: "'monitors' in groups"

      - block:
          - name: Check If ceph mon is located at ceph node
            become: true
            shell: "pgrep -a ceph-mon"
            register: ceph_mon
            ignore_errors: true

          - name: Set ceph client to be local ceph node If ceph-mon present
            set_fact:
              ceph_client: "{{ inventory_hostname }}"
            when: ceph_mon.rc == 0

          # Check if Ceph cluster name is used
          - name: Get a name of Ceph cluster
            become: true
            shell: "ps -p $(pidof ceph-mon) -o args --no-headers | grep -o 'cluster.*' | cut -d' ' -f2"
            register: ceph_cluster_name
            delegate_to: "{{ ceph_client }}"

          - name: Set path to ceph configuration
            set_fact:
              ceph_conf_option: >-
                  {{ (ceph_cluster_name.stdout | length > 0) | ternary('-c /etc/ceph/' ~ ceph_cluster_name.stdout ~ '.conf', '') }}
        when:
            - overcloud_version|int >= 14
            - "'ceph' in group_names"

      # Temporarily disable ceph rebalance on OSP < 14
      - name: temporarily disable ceph rebalance
        become: true
        command: "{{ item }}"
        when:
          - "'ceph' in group_names"
          - overcloud_version|int < 14
        delegate_to: "{{ ceph_client }}"
        with_items:
            - 'ceph osd set noout'
            - 'ceph osd set norebalance'

      # Temporarily disable ceph rebalance on OSP >= 14
      - name: temporarily disable ceph rebalance
        become: true
        command: "{{ item }}"
        when:
          - "'ceph' in group_names"
          - overcloud_version|int >= 14
          - overcloud_version|int < 17
        delegate_to: "{{ ceph_client }}"
        with_items:
            - "{{ container_runtime }} exec ceph-mon-{{ ceph_client }} ceph {{ ceph_conf_option }} osd set noout"
            - "{{ container_runtime }} exec ceph-mon-{{ ceph_client }} ceph {{ ceph_conf_option }} osd set norebalance"

      # Temporarily disable ceph rebalance on OSP >= 17
      - name: temporarily disable ceph rebalance
        become: true
        command: "{{ item }}"
        when:
          - "'ceph' in group_names"
          - overcloud_version|int >= 17
        delegate_to: "{{ ceph_client }}"
        with_items:
            - "cephadm shell -- ceph pg stat"
            - "cephadm shell -- ceph -s"
            - "cephadm shell -- ceph config dump"
            - "cephadm shell -- ceph df"
            - "cephadm shell -- ceph osd set noout"
            - "cephadm shell -- ceph osd set norebalance"

      # We check with systemctl if system has finished booting up
      # but on RHEL7 we don't have --wait option so we check only
      # for the state. We accept running or degraded as some
      # services seem to flap after bootup but work fine.
      - name: reboot the node
        become: true
        reboot:
            reboot_timeout: "{{ install.reboot.timeout }}"
            test_command: >-
                systemctl is-system-running | grep -e running -e degraded

      # Re-enable ceph rebalance on OSP < 14
      - name: reenable ceph rebalance
        become: true
        command: "{{ item }}"
        when:
          - "'ceph' in group_names"
          - overcloud_version|int < 14
        delegate_to: "{{ ceph_client }}"
        with_items:
            - 'ceph osd unset noout'
            - 'ceph osd unset norebalance'

      # Re-enable ceph rebalance on OSP >= 14
      - name: reenable ceph rebalance
        become: true
        command: "{{ item }}"
        when:
          - "'ceph' in group_names"
          - overcloud_version|int >= 14
          - overcloud_version|int < 17
        delegate_to: "{{ ceph_client }}"
        with_items:
            - "{{ container_runtime }} exec ceph-mon-{{ ceph_client }} ceph {{ ceph_conf_option }} osd unset noout"
            - "{{ container_runtime }} exec ceph-mon-{{ ceph_client }} ceph {{ ceph_conf_option }} osd unset norebalance"


      # Re-enable ceph rebalance on OSP >= 17
      - name: reenable ceph rebalance
        become: true
        command: "{{ item }}"
        when:
          - "'ceph' in group_names"
          - overcloud_version|int >= 17
        delegate_to: "{{ ceph_client }}"
        with_items:
            - "cephadm shell -- ceph osd unset noout"
            - "cephadm shell -- ceph osd unset norebalance"

      - name: wait for OSDs to come back on OSP < 14
        become: true
        command: ceph pg stat
        register: active_osd
        until: active_osd.stdout.find("active+clean") > -1
        retries: 24
        delay: 15
        when:
          - "'ceph' in group_names"
          - overcloud_version|int < 14
        delegate_to: "{{ ceph_client }}"

      - name: wait for OSDs to come back on OSP >= 14
        become: true
        command: "{{ container_runtime }} exec ceph-mon-{{ ceph_client }} ceph {{ ceph_conf_option }} pg stat"
        register: active_osd
        until: active_osd.stdout.find("active+clean") > -1
        retries: 24
        delay: 15
        when:
          - "'ceph' in group_names"
          - overcloud_version|int >= 14
          - overcloud_version|int < 17
        delegate_to: "{{ ceph_client }}"

      - name: wait for OSDs to come back on OSP >= 17
        become: true
        command: "cephadm shell -- ceph pg stat"
        register: active_osd
        until: active_osd.stdout.find("active+clean") > -1
        retries: 24
        delay: 15
        when:
          - "'ceph' in group_names"
          - overcloud_version|int >= 17
        delegate_to: "{{ ceph_client }}"

      - name: check clock_skew on ceph cluster on OSP < 14
        become: true
        shell: |
            ceph status | grep 'Monitor clock skew detected' || echo 'ALL_GOOD'
        register: clock_skew
        when:
          - "'ceph' in group_names"
          - overcloud_version|int < 14
        delegate_to: "{{ ceph_client }}"

      - name: check clock_skew on ceph cluster on OSP >= 14
        become: true
        shell: |
            {{ container_runtime }} exec ceph-mon-{{ ceph_client }} ceph {{ ceph_conf_option }} status | grep 'Monitor clock skew detected' || echo 'ALL_GOOD'
        register: clock_skew
        when:
          - "'ceph' in group_names"
          - overcloud_version|int >= 14
          - overcloud_version|int < 17
        delegate_to: "{{ ceph_client }}"

      - name: check clock_skew on ceph cluster on OSP >= 17
        become: true
        shell: |
            cephadm shell -- ceph status | grep 'Monitor clock skew detected' || echo 'ALL_GOOD'
        register: clock_skew
        when:
          - "'ceph' in group_names"
          - overcloud_version|int >= 17
        delegate_to: "{{ ceph_client }}"

      - name: check ceph cluster status on OSP < 14
        become: true
        command: ceph status
        register: ceph_health
        until: ceph_health.stdout.find("HEALTH_OK") > -1
        retries: 30
        delay: 5
        delegate_to: "{{ ceph_client }}"
        when:
            - "'ceph' in group_names"
            - "groups['ceph']|difference(groups['unused']|default([]))|length >= 3"
            - "'ALL_GOOD' in clock_skew"
            - overcloud_version|int < 14

      - name: check ceph cluster status on OSP >= 14
        become: true
        command: "{{ container_runtime }} exec ceph-mon-{{ ceph_client }} ceph {{ ceph_conf_option }} status"
        register: ceph_health
        until: ceph_health.stdout.find("HEALTH_OK") > -1
        retries: 30
        delay: 5
        delegate_to: "{{ ceph_client }}"
        when:
            - "'ceph' in group_names"
            - "groups['ceph']|difference(groups['unused']|default([]))|length >= 3"
            - "'ALL_GOOD' in clock_skew"
            - overcloud_version|int >= 14
            - overcloud_version|int < 17

      - name: check ceph cluster status on OSP >= 17
        become: true
        command: "cephadm shell -- ceph status"
        register: ceph_health
        until: ceph_health.stdout.find("HEALTH_OK") > -1
        retries: 30
        delay: 5
        delegate_to: "{{ ceph_client }}"
        when:
            - "'ceph' in group_names"
            - "groups['ceph']|difference(groups['unused']|default([]))|length >= 3"
            - "'ALL_GOOD' in clock_skew"
            - overcloud_version|int >= 17

      - name: check ceph cluster status with clock skew on OSP < 14
        become: true
        command: ceph status
        register: ceph_health
        until: ceph_health.stdout.find("HEALTH_WARN") > -1 or ceph_health.stdout.find("HEALTH_OK") > -1
        retries: 30
        delay: 5
        delegate_to: "{{ ceph_client }}"
        when:
            - "'ceph' in group_names"
            - "groups['ceph']|difference(groups['unused']|default([]))|length >= 3"
            - overcloud_version|int < 14

      - name: check ceph cluster status with clock skew on OSP >=14
        become: true
        command: "{{ container_runtime }} exec ceph-mon-{{ ceph_client }} ceph {{ ceph_conf_option }} status"
        register: ceph_health
        until: ceph_health.stdout.find("HEALTH_WARN") > -1 or ceph_health.stdout.find("HEALTH_OK") > -1
        retries: 30
        delay: 5
        delegate_to: "{{ ceph_client }}"
        when:
            - "'ceph' in group_names"
            - "groups['ceph']|difference(groups['unused']|default([]))|length >= 3"
            - overcloud_version|int >= 14
            - overcloud_version|int < 17

      - name: check ceph cluster status with clock skew on OSP >=17
        become: true
        command: "cephadm shell -- ceph status"
        register: ceph_health
        until: ceph_health.stdout.find("HEALTH_WARN") > -1 or ceph_health.stdout.find("HEALTH_OK") > -1
        retries: 30
        delay: 5
        delegate_to: "{{ ceph_client }}"
        when:
            - "'ceph' in group_names"
            - "groups['ceph']|difference(groups['unused']|default([]))|length >= 3"
            - overcloud_version|int >= 17
