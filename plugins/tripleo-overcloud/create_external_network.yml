---
# This playbook is used to enable external network access to virthost or baremetal deployments and it is
# intended to be used as post-deployment step. It does not create private networks and router as it is
# users responsibility.
# This playbook gathers data from template_base used in ospd installer!
# Playbook is idempotent
# This playbook uses ansible openstack modules and assumes the undercloud already has
# a virtualenv containing shade.
# venv is created in playbooks/installer/ospd/ospd_inventory_update.yml as /var/tmp/venv_shade

- name: External network creation
  hosts: undercloud
  gather_facts: yes
  any_errors_fatal: true
  vars_files:
      - "{{ install.public.subnet }}"
  vars:
      source_dir: "{{ install.deployment.files }}"
      network_environment_file: "network-environment{{ (install.network.protocol == 'ipv6') | ternary('-v6','') }}.yaml"
      physnet_name: datacentre
      template_base: "{{ ansible_user_dir }}/{{ source_dir | basename }}"
  tasks:
      - name: find a server with the nova control plane service running
        shell: |
            test -f {{ ansible_user_dir }}/{{ install.overcloud.stack }}rc.v3 && \
                source {{ ansible_user_dir }}/{{ install.overcloud.stack }}rc.v3 || \
                source {{ ansible_user_dir }}/{{ install.overcloud.stack }}rc
            nova service-list | grep nova-scheduler | awk '{print $6}' | head -1
        register: nova_host

      - name: server found
        debug: msg="{{ nova_host.stdout.split('.') | first }}"

      - name: get the default floating ip pool name from the server
        shell: "awk -F'\"' '/default_floating_pool/ {print $4}' /etc/puppet/hieradata/service_configs.json"
        register: pool_name
        delegate_to: "{{ nova_host.stdout.split('.') | first }}"
        become: yes

# FIXME(yfried): this is commented because virthost solution is misconfiguring vlan. Need to reevaluate the vlan indicators
#      - name: Check if vlan is enabled for public network - get vlan trunks
#        command: "grep -E \"^network_vlan_ranges\\s*=\" /etc/neutron/plugin.ini"
#        register: vlan_trunks
#        delegate_to: "{{ first_controller }}"
#        become: yes

      - name: check the deployment network configuration file
        find:
            paths: "{{ template_base }}"
            patterns: "{{ network_environment_file }}"
            recurse: yes
        register: network_environment_file_path

      # do not fail on missing template file.
      # if template is missing then network islation is not used
      # and the default parameters will be used for deployment

      - name: read deployment network configuration
        command: "cat {{ network_environment_file_path.files[0].path }}"
        register: network_template_out
        when: network_environment_file_path.matched > 0

      - name: load deployment network configuration as YAML
        set_fact:
            network_template: "{{ network_template_out.stdout | from_yaml }}"
        when: network_environment_file_path.matched > 0

      # for openstack v11 the OS_TENANT_NAME is replaced with OS_PROJECT_NAME
      # Trying to resolve OS_PROJECT_NAME and then OS_TENANT_NAME

      - name: create the external network
        vars:
            # FIXME(yfried): this is commented because virthost solution is misconfiguring vlan. Need to reevaluate the vlan indicators
            # # If 'datacentre' physnet is in vlan trunk, this means ext-net must be of vlan type
            # physnet_type: "{{ (physnet_name in vlan_trunks.stdout) | ternary('vlan', 'flat') }}"
            physnet_type: "{{ ('hypervisor' in groups and install.hybrid is not defined or 'bmc' in groups and install.hybrid is not defined) | ternary('flat', 'vlan') }}"
            vlan_id: "{{ install.get('external', {}).vlan | default(((network_template|default({})).parameter_defaults|default({})).ExternalNetworkVlanID|default('')) }}"
            # Here can't be used {{ path_venv }}, because it's not a Jinja template
            ansible_python_interpreter: "/var/tmp/venv_shade/bin/python"
            network_name: "{{ install.public.get('net', {}).name|default(pool_name.stdout_lines|last) }}"
        os_network:
            # Required for SSL
            validate_certs: no
            cloud: overcloud
            name: "{{ network_name }}"
            external: yes
            shared: no
            provider_physical_network: "{{ physnet_name }}"
            provider_network_type: "{{ physnet_type }}"
            provider_segmentation_id: "{{ ('vlan' == physnet_type) | ternary(vlan_id, omit) }}"
        register: net_create
        delegate_to: "{{ groups.shade | first }}"

      - name: print network details to console
        shell: |
            test -f {{ ansible_user_dir }}/{{ install.overcloud.stack }}rc.v3 && \
                source {{ ansible_user_dir }}/{{ install.overcloud.stack }}rc.v3 || \
                source {{ ansible_user_dir }}/{{ install.overcloud.stack }}rc
            neutron net-show {{ net_create.network.name }}
        tags: skip_ansible_lint

      # OSPD "External*" data can't be used to discover subnet details because:
      #     1) IPv6 public network is not supported as public network
      #     2) CIDR arithmetic is complicated. Only implement it when #1 is supported
      - name: create the external subnet
        vars:
            # Here can't be used {{ path_venv }}, because it's not a Jinja template
            ansible_python_interpreter: "/var/tmp/venv_shade/bin/python"
            # It's cleaner to define top defaults first
            pool: "{{ subnet.allocation_pool|default({}) }}"
        os_subnet:
            # Required for SSL
            validate_certs: no
            cloud: overcloud
            name: external_subnet
            network_name: "{{ net_create.network.name }}"
            enable_dhcp: no
            cidr: "{{ subnet.cidr }}"
            gateway_ip: "{{ subnet.gateway }}"
            allocation_pool_start: "{{ pool.start | default(omit) }}"
            allocation_pool_end: "{{ pool.end | default(omit) }}"
        register: subnet_create
        delegate_to: "{{ groups.shade | first }}"

      - name: print subnet details to console
        shell: |
            test -f {{ ansible_user_dir }}/{{ install.overcloud.stack }}rc.v3 && \
                source {{ ansible_user_dir }}/{{ install.overcloud.stack }}rc.v3 || \
                source {{ ansible_user_dir }}/{{ install.overcloud.stack }}rc
            neutron subnet-show {{ subnet_create.subnet.name }}
        tags: skip_ansible_lint
