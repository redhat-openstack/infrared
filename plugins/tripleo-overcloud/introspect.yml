- name: Auto generate instackenv.json for virt
  include: "{{ overcloud_virt | default('hypervisor.yml') }}"
  tags:
      - hypervisor
      - ironic
      - instack
  when: "'hypervisor' in groups"

- name: Auto generate instackenv.json for ovb
  include: "{{ overcloud_ovb | default('ovb.yml') }}"
  tags:
     - ironic
     - instack
     - ovb
  when: "'bmc' in groups"

- name: Introspect our machines
  hosts: undercloud
  gather_facts: no
  any_errors_fatal: true
  vars:
      undercloud_provision_cidr: "{{ ansible_br_ctlplane.ipv4.network }}/{{ ansible_br_ctlplane.ipv4.netmask }}"
      instack_input: "{{ (install.instackenv|default({})).file | default('') }}"
  tasks:
      - name: inject instackenv file if provided by the user
        tags: ironic
        copy:
            src: "{{ instack_input }}"
            dest: "~/{{ instack_input | basename }}"
        when: instack_input is defined
        register: inject_instackenv

      - name: verify that instackenv json file exists
        stat:
            path: "~/{{ (instack_input or 'instackenv.json') | basename }}"
        register: instack_file_path
        tags: ironic

      - name: fail if instackenv file is missing
        fail:
            msg: instackenv file is missing
        when: not instack_file_path.stat.exists
        tags: ironic

      - name: register hosts to instack
        shell: |
            source ~/stackrc
            openstack baremetal import --json {{ instack_file_path.stat.path }}
        tags:
            - ironic
            # FIXME(yfried) use "--os-cloud" instead of "source rc" and replace with command
            - skip_ansible_lint

      # FIXME(yfried): unify in above shell?
      - name: assign the kernel and ramdisk before introspection begins
        shell: |
            source ~/stackrc
            openstack baremetal configure boot
        tags:
            - ironic
            # FIXME(yfried) use "--os-cloud" instead of "source rc" and replace with command
            - skip_ansible_lint

      - name: set the root device for baremetal nodes (with size hint)
        shell: |
            source ~/stackrc
            NODE_UUID=$(ironic node-list | grep {{ item }} | awk '{print $2}' )
            ironic node-update ${NODE_UUID} add properties/root_device='{"size": {{ hostvars[item].disk  }} }'
        with_items: "{{ groups['overcloud_nodes'] | default([])}}"
        when: "'bmc' in groups"

      # Because introspection is faulty and tricky especially on baremetals
      # we need to check multiple times if any failure occured. Reasonable time
      # for this process to take is < 10 minutes no matter how many nodes for baremetals.
      # Virtual setups don't suffer from long timeouts caused by delays in boot
      # process, BIOS timeouts and errors in firmware so they are covered by such timeout
      # seamlessly. This must be async task because we need to enforce explicit timeout
      # for this process, otherwise timeout is controlled by ironic and seriously long
      # (usually one must wait for 1 hour if any failure on any node occurs).

      # FIXME (atalmor) this task is a workaround for bugzilla 1452610, should be removed when bug is fixed
      - name: veryfied ironic service is up
        become: true
        service:
          name: openstack-ironic-inspector-dnsmasq
          state: started
          enabled: yes

      - name: start node introspection
        shell: |
            source ~/stackrc
            openstack baremetal introspection bulk start
        tags:
            # FIXME(yfried) use "--os-cloud" instead of "source rc" and replace with command
            - skip_ansible_lint
        register: bulk_intro_result
        poll: 50
        async: 600
        retries: 10
        delay: 90
        ignore_errors: yes

      # Async tasks in Ansible don't have rc defined if they failed (for some reason) which makes registered
      # variable different for various outcomes and just using "result" key is not possible here.
      # Following fact will construct properly introspection result properly from possibly
      # different statutes presented by output of async task.
      - set_fact:
            bulk_intro_ok: "{{ true if bulk_intro_result.rc is defined and bulk_intro_result.rc == 0 else false }}"

      # If bulk introspection failed, play introspection_recovery playbook which runs node-by-node introspection
      # and also helps with debugging and recovery.
      - name: Recover from errors during bulk introspection
        include: tasks/introspection_recovery.yml
        when: not bulk_intro_ok
