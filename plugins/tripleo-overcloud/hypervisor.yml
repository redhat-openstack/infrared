- name: Gather facts for Hypervisor
  hosts: hypervisor
  gather_facts: yes
  any_errors_fatal: true

- name: Generate the instackenv.json
  hosts: undercloud
  gather_facts: no
  any_errors_fatal: true
  tasks:
      - name: Retrieve public key from private key to localhost
        command: "ssh-keygen -y -f ~/.ssh/id_rsa"
        register: uc_pubkey_result

      - name: insert the public key to the known hosts in hypervisor
        authorized_key:
            user: "{{ ansible_ssh_user }}"
            key: "{{ uc_pubkey_result.stdout }}"
        delegate_to: hypervisor

      - include: tasks/ironic_pxe_ipmitool.yml
        vars:
            pxe_ipmitool_req_packs:
                - python-setuptools
                - python-virtualbmc
                - ipmitool
            vbmc_start_port: 6230
        when: install.version|default(undercloud_version) | openstack_release >= 11

      - name: grab undercloud private key
        command: "cat ~/.ssh/id_rsa"
        register: uc_pkey_result

      - name: discover provsion network name
        include: tasks/discover_provision_net.yml
        vars:
            uc_provision_net: "ctlplane"
        when: provison_virsh_network_name is not defined

      - fail:
            msg: "The provision network cannot be discovered. Please rerun infrared command with -e provison_virsh_network_name=<net_name>"
        when: provison_virsh_network_name is not defined

      - name: get information about vm's from hypervisor
        delegate_to: hypervisor
        shell: |
            NODE_XML=`virsh dumpxml {{ item }}`
            disks_list="["
            for dsk in $(virsh domblklist {{ item }} | tail -n +3 | awk '{print $1}'); do
                disks_list="${disks_list}\"${dsk}\","
            done
            disks_list="${disks_list}]"
            disks_list="$(echo ${disks_list} | sed 's/,]/]/g')"

            echo "{
                'name': '{{ item }}',
                'arch': '`echo "$NODE_XML" | grep arch | cut -d\' -f2`',
                'memory_kibs': '`echo "$NODE_XML" | grep currentMemory | cut -d\< -f2 | cut -d\> -f2`',
                'mac': '`echo "$NODE_XML" | grep {{ provison_virsh_network_name }} -B 1 | grep mac | cut -d\' -f2`',
                'cpu': '`echo "$NODE_XML" | grep vcpu | cut -d\< -f2 | cut -d\> -f2`',
                'disk_bytes': '`virsh domblkinfo {{ item }} vda | grep -e Capacity | cut -d\: -f2 | xargs`',
                'disks': '${disks_list}',
            }"
        with_items: "{{ groups['overcloud_nodes'] }}"
        register: nodes_info
        tags:
            - skip_ansible_lint

      - name: Read baremetal nodes got from user input on hybrid deployment
        include_vars:
            file: "{{ install.hybrid }}"
            name: bm_nodes
        when: install.hybrid is defined

      - name: prepare instackenv.json file
        vars:
            instack_input: "{{ (install.instackenv|default({})).file|default('') }}"
            instack_output: "~/instackenv.json"
            # json file shouldn't hold newlines
            undercloud_private_key: "{{ uc_pkey_result.stdout_lines | join('\\n')}}"
        template:
            src: templates/instackenv.json.j2
            dest: "{{ instack_output }}"
        when: not instack_input or install.hybrid|default('')

      # Using delegete here because of
      # https://github.com/ansible/ansible/issues/16972
      # This issue causes an exception when that playbook is included with the false condition
      - name: power off overcloud nodes
        virt:
            name: "{{ item }}"
            state: destroyed
        with_items: "{{ groups['overcloud_nodes'] }}"
        delegate_to: hypervisor
