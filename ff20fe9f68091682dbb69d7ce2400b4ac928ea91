{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "5ea926cf_c87e181f",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1016110
      },
      "writtenOn": "2021-05-17T20:07:16Z",
      "side": 1,
      "message": "So is the scope just the virsh infrared plugin? \n\nSorry if I\u0027m picky about this, but it may speed up the reviews if it\u0027s marked in the commit message",
      "revId": "ff20fe9f68091682dbb69d7ce2400b4ac928ea91",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "113721d2_978c629e",
        "filename": "plugins/virsh/tasks/netip_natted.yml",
        "patchSetId": 1
      },
      "lineNbr": 14,
      "author": {
        "id": 1016895
      },
      "writtenOn": "2021-05-18T10:48:00Z",
      "side": 1,
      "message": "This could be done like: \"{{ vm_wait_retry_counts | default(50) }}\"\n\nThat way there\u0027s no need to hunt for there the variable is set. It also means that the variable can be set in the inventory or group_vars, rather than forcing the use of extra-vars.",
      "range": {
        "startLine": 14,
        "startChar": 0,
        "endLine": 14,
        "endChar": 39
      },
      "revId": "ff20fe9f68091682dbb69d7ce2400b4ac928ea91",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "95a9a4b5_f07ac56b",
        "filename": "plugins/virsh/tasks/netip_natted.yml",
        "patchSetId": 1
      },
      "lineNbr": 14,
      "author": {
        "id": 1011165
      },
      "writtenOn": "2021-05-18T19:04:52Z",
      "side": 1,
      "message": "Done.",
      "parentUuid": "113721d2_978c629e",
      "range": {
        "startLine": 14,
        "startChar": 0,
        "endLine": 14,
        "endChar": 39
      },
      "revId": "ff20fe9f68091682dbb69d7ce2400b4ac928ea91",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "10fdbbe3_472bfd22",
        "filename": "plugins/virsh/tasks/netip_natted.yml",
        "patchSetId": 1
      },
      "lineNbr": 15,
      "author": {
        "id": 1016895
      },
      "writtenOn": "2021-05-18T10:48:00Z",
      "side": 1,
      "message": "Would it perhaps make better sense to increase the delay? I\u0027m not sure what would cause a VM to take more than 3.5 mins to start and get an IP address... but perhaps increasing the delay would extend the timeout and achieve the same result without the extra log output caused by the retries.",
      "range": {
        "startLine": 15,
        "startChar": 0,
        "endLine": 15,
        "endChar": 10
      },
      "revId": "ff20fe9f68091682dbb69d7ce2400b4ac928ea91",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "1674ca1a_b0521fa6",
        "filename": "plugins/virsh/tasks/netip_natted.yml",
        "patchSetId": 1
      },
      "lineNbr": 15,
      "author": {
        "id": 1011165
      },
      "writtenOn": "2021-05-18T19:03:33Z",
      "side": 1,
      "message": "Changed to 30 retries and 10 delays which gives 5 minutes in total. Concerning the purpose, I have \"iloveopenstack\" machine with spinning disks where I experiment some thing so I see this failure quite often.",
      "parentUuid": "10fdbbe3_472bfd22",
      "range": {
        "startLine": 15,
        "startChar": 0,
        "endLine": 15,
        "endChar": 10
      },
      "revId": "ff20fe9f68091682dbb69d7ce2400b4ac928ea91",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "01361489_7f630046",
        "filename": "plugins/virsh/tasks/netip_natted.yml",
        "patchSetId": 1
      },
      "lineNbr": 15,
      "author": {
        "id": 1016895
      },
      "writtenOn": "2021-05-19T08:08:18Z",
      "side": 1,
      "message": "OK, so the theory is that the lack of an address is caused by the IO contention when a group of VM\u0027s start?\n\nI wonder if there\u0027s perhaps some other way of deterministically identifying whether the VM\u0027s are all up yet. But that\u0027s perhaps a little too much effort to put into the problem.",
      "parentUuid": "1674ca1a_b0521fa6",
      "range": {
        "startLine": 15,
        "startChar": 0,
        "endLine": 15,
        "endChar": 10
      },
      "revId": "ff20fe9f68091682dbb69d7ce2400b4ac928ea91",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    }
  ]
}